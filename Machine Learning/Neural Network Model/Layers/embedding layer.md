
طبقة بتعمل زى توكينيز جوة النتورك
بتخلي التوكين الي معمولة من رقم لفيكتور من الارقام
فا تبقى دقيقة اكتر


embeddings is to represent the word in a dense vector while making sure that similar words are close to each other in the embedding space

--> What is a Dense Vector  :
vector representing the word

--> Embedding Space :
is where your embedded data lives..
المسافه بين نقطتين فيه بتوضح مدى تشابه الكلمتين دول ف المعنى
## Links
[244 - What are embedding layers in keras? - YouTube](https://www.youtube.com/watch?v=nam2zR7p7Os)

https://www.youtube.com/watch?v=5MaWmXwxFNQ&list=PLcWfeUsAys2nPgh-gYRlexc6xvscdvHqX&index=16&ab_channel=AssemblyAI